

import os
from pdf2image import convert_from_path
import pytesseract
from nltk.tokenize import sent_tokenize
from transformers import AutoTokenizer, AutoModel
import torch
import faiss
import numpy as np
import nltk

nltk.download("punkt")

# ✅ Tesseract 경로 (수동으로 설정 필요)
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"

# ✅ 임베딩 모델 설정 (bge-small-en)
device = "cuda" if torch.cuda.is_available() else "cpu"
model_name = "../models/bge-small-en"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModel.from_pretrained(model_name).to(device)


# ✅ 1. PDF → 이미지 → 텍스트 추출
def extract_sentences_from_image_pdf(pdf_path):
    images = convert_from_path(pdf_path, dpi=300)
    all_text = ""
    for img in images:
        text = pytesseract.image_to_string(img, lang="eng")  # or "kor+eng"
        all_text += text + "\n"
    return sent_tokenize(all_text)


# ✅ 2. 문장 리스트 → 임베딩
def embed_sentences(sentences):
    inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors="pt").to(device)
    with torch.no_grad():
        outputs = model(**inputs)
        embeddings = outputs.last_hidden_state[:, 0]  # CLS token
    return embeddings.cpu().numpy()


# ✅ 3. FAISS 저장
def save_faiss_index(embeddings, sentences, out_dir="vector_index"):
    os.makedirs(out_dir, exist_ok=True)
    dim = embeddings.shape[1]
    index = faiss.IndexFlatL2(dim)
    index.add(embeddings)
    faiss.write_index(index, os.path.join(out_dir, "faiss.index"))

    with open(os.path.join(out_dir, "sentences.txt"), "w", encoding="utf-8") as f:
        for s in sentences:
            f.write(s.strip() + "\n")

    print(f"✅ 저장 완료: {out_dir}/faiss.index + sentences.txt")


# ✅ 실행
def run(pdf_path):
    print("📄 PDF → 문장 추출 중...")
    sentences = extract_sentences_from_image_pdf(pdf_path)
    print(f"✅ 문장 수: {len(sentences)}")

    print("🔗 벡터화 중...")
    embeddings = embed_sentences(sentences)

    print("💾 FAISS 인덱스 저장 중...")
    save_faiss_index(embeddings, sentences)


# 예시 실행
if __name__ == "__main__":
    run("../data/pdfs/part1.pdf")  # <- 여기에 OCR 대상 PDF 경로 넣기









[nltk_data] Error loading punkt: <urlopen error [WinError 10054] 현재
[nltk_data]     연결은 원격 호스트에 의해 강제로 끊겼습니다>
📄 PDF → 문장 추출 중...
---------------------------------------------------------------------------
LookupError                               Traceback (most recent call last)
Cell In[2], line 72
     70 # 예시 실행
     71 if __name__ == "__main__":
---> 72     run("../data/pdfs/part1.pdf")  # <- 여기에 OCR 대상 PDF 경로 넣기

Cell In[2], line 60
     58 def run(pdf_path):
     59     print("📄 PDF → 문장 추출 중...")
---> 60     sentences = extract_sentences_from_image_pdf(pdf_path)
     61     print(f"✅ 문장 수: {len(sentences)}")
     63     print("🔗 벡터화 중...")

Cell In[2], line 30
     28     text = pytesseract.image_to_string(img, lang="eng")  # or "kor+eng"
     29     all_text += text + "\n"
---> 30 return sent_tokenize(all_text)

File c:\Users\mgoog1.ko\AppData\Local\Programs\Python\Python310\lib\site-packages\nltk\tokenize\__init__.py:119, in sent_tokenize(text, language)
    109 def sent_tokenize(text, language="english"):
    110     """
    111     Return a sentence-tokenized copy of *text*,
    112     using NLTK's recommended sentence tokenizer
   (...)
...
    - 'C:\\nltk_data'
    - 'D:\\nltk_data'
    - 'E:\\nltk_data'
**********************************************************************
