import os
from pdf2image import convert_from_path
import pytesseract
from nltk.tokenize import sent_tokenize
from transformers import AutoTokenizer, AutoModel
import torch
import faiss
import numpy as np
import nltk

nltk.download("punkt")

# âœ… Tesseract ê²½ë¡œ (ìˆ˜ë™ìœ¼ë¡œ ì„¤ì • í•„ìš”)
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"

# âœ… ì„ë² ë”© ëª¨ë¸ ì„¤ì • (bge-small-en)
device = "cuda" if torch.cuda.is_available() else "cpu"
model_name = "BAAI/bge-small-en"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModel.from_pretrained(model_name).to(device)


# âœ… 1. PDF â†’ ì´ë¯¸ì§€ â†’ í…ìŠ¤íŠ¸ ì¶”ì¶œ
def extract_sentences_from_image_pdf(pdf_path):
    images = convert_from_path(pdf_path, dpi=300)
    all_text = ""
    for img in images:
        text = pytesseract.image_to_string(img, lang="eng")  # or "kor+eng"
        all_text += text + "\n"
    return sent_tokenize(all_text)


# âœ… 2. ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸ â†’ ì„ë² ë”©
def embed_sentences(sentences):
    inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors="pt").to(device)
    with torch.no_grad():
        outputs = model(**inputs)
        embeddings = outputs.last_hidden_state[:, 0]  # CLS token
    return embeddings.cpu().numpy()


# âœ… 3. FAISS ì €ì¥
def save_faiss_index(embeddings, sentences, out_dir="vector_index"):
    os.makedirs(out_dir, exist_ok=True)
    dim = embeddings.shape[1]
    index = faiss.IndexFlatL2(dim)
    index.add(embeddings)
    faiss.write_index(index, os.path.join(out_dir, "faiss.index"))

    with open(os.path.join(out_dir, "sentences.txt"), "w", encoding="utf-8") as f:
        for s in sentences:
            f.write(s.strip() + "\n")

    print(f"âœ… ì €ì¥ ì™„ë£Œ: {out_dir}/faiss.index + sentences.txt")


# âœ… ì‹¤í–‰
def run(pdf_path):
    print("ğŸ“„ PDF â†’ ë¬¸ì¥ ì¶”ì¶œ ì¤‘...")
    sentences = extract_sentences_from_image_pdf(pdf_path)
    print(f"âœ… ë¬¸ì¥ ìˆ˜: {len(sentences)}")

    print("ğŸ”— ë²¡í„°í™” ì¤‘...")
    embeddings = embed_sentences(sentences)

    print("ğŸ’¾ FAISS ì¸ë±ìŠ¤ ì €ì¥ ì¤‘...")
    save_faiss_index(embeddings, sentences)


# ì˜ˆì‹œ ì‹¤í–‰
if __name__ == "__main__":
    run("../data/pdfs/part1.pdf")  # <- ì—¬ê¸°ì— OCR ëŒ€ìƒ PDF ê²½ë¡œ ë„£ê¸°
